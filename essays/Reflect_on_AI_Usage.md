---
layout: essay
type: essay
title: "How to use Skynet in the Classroom"
# All dates must be YYYY-MM-DD format!
date: 2025-05-9
published: false
labels:
  - AI
  - ChatGPT
  - Grok
---

## I. Introduction
  Artificial Intelligence (AI) has become a transformative force in modern education, particularly within the field of Software Engineering. Its integration into academic settings has revolutionized how students engage with complex concepts, develop practical skills, and approach problem-solving. In the context of ICS 314, a Software Engineering course, AI tools have played a pivotal role in enhancing learning experiences by facilitating tasks such as code generation, debugging, research, and project management. This essay reflects on my personal experiences with AI tools, specifically ChatGPT and Grok, within ICS 314, evaluating their utility, impact, and potential for future integration. By examining specific applications, challenges, and opportunities, this analysis aims to provide a comprehensive perspective on AI’s role in software engineering education.

  The primary AI tools utilized in this course were ChatGPT and Grok. ChatGPT, a widely accessible conversational model, proved effective for general programming tasks and fact-checking but often struggled with complex or nuanced coding challenges. Grok, developed by xAI, demonstrated greater reliability and precision in generating syntactically correct and contextually appropriate code. These tools were employed for various purposes, including code generation, debugging, concept exploration, and project development, each contributing uniquely to my learning journey.

## II. Personal Experience with AI
  Below, I detail my experiences with AI across various elements of ICS 314, providing specific examples, prompts, and reflections on their utility, benefits, and limitations.

  Experience WODsFor Experience WODs (Workout of the Day), I leveraged AI to avoid Did Not Finish (DNF) scenarios, ensuring timely completion within acceptable submission windows. For example, in E18, a WOD focused on functional programming with Underscore.js, I used Grok with the prompt: “Write a function using Underscore.js to filter and map an array of objects based on the following instructions: [WOD instructions].” Grok generated a working solution that I adapted to meet specific requirements. The benefit was significant: AI reduced the time spent on trial-and-error, allowing me to focus on understanding the logic. However, over-reliance risked superficial learning, as I occasionally prioritized completion over deep comprehension.

  In-class Practice WODsDuring practice WODs, I used AI post-session to analyze my approach. After attempting a WOD on reactive programming, I prompted ChatGPT: “Review my code [pasted code] and suggest optimizations for reactive programming with Meteor.” The suggestions helped refine my implementation, but ChatGPT occasionally provided generic advice that lacked context. Sharing AI outputs with peers revealed variations in AI responses, prompting me to refine my prompts for specificity. This collaborative comparison enhanced my prompting skills but highlighted AI’s inconsistency with context-specific guidance.

  In-class WODsFor graded in-class WODs, AI was instrumental in ensuring full completion under time constraints. In a WOD involving MongoDB queries, I used Grok with the prompt: “Generate MongoDB query code to retrieve and sort documents based on [WOD specifications].” Grok’s accurate output supplemented my understanding, enabling me to meet deadlines. However, as WODs grew complex, spanning multiple files, I had to provide detailed prompts, including file structures, to avoid irrelevant responses. The cost was the time spent crafting precise prompts, but the benefit was reliable code that accelerated task completion.

  EssaysAI assisted with technical aspects of essay writing, such as Markdown formatting and GitHub portfolio management. For instance, I prompted ChatGPT: “Provide a Markdown template for a professional essay with sections and subsections.” The template streamlined formatting, saving time. However, I avoided using AI for content generation due to the personal nature of the essays. I also found AI unreliable for spell-checking without altering my intended tone, so I relied on manual proofreading to preserve authenticity.

  Final ProjectAI was invaluable for the final project, aiding in feature implementation, debugging, and workflow optimization. For a login feature using Meteor, I used Grok with the prompt: “Generate Meteor code for a secure user login system with error handling.” Grok’s solution provided a robust starting point, though debugging server-side issues required peer collaboration, as AI struggled to account for our specific environment. AI also improved our GitHub workflow; I prompted: “Explain best practices for Git branching and merging in a team project.” The guidance reduced merge conflicts. While AI couldn’t address all project complexities, it significantly accelerated development by breaking tasks into manageable components.

  Learning a Concept/TutorialAI facilitated concept exploration by allowing me to adjust the depth of explanations. For example, to understand reactive programming, I prompted Grok: “Explain reactive programming in Meteor at a beginner level, then provide an advanced example.” Grok’s tiered response clarified the concept and provided practical code. Occasionally, AI assumed prior knowledge, requiring follow-up prompts like: “Define [term] in simpler terms.” The flexibility to “zoom in and out” was a key benefit, though it required active prompt refinement to avoid overwhelming detail.

  Answering a Question in Class or Discord I refrained from using AI to answer questions in class or on Discord, prioritizing personal confidence in my responses. My rationale was that peers could access AI themselves, making anecdotal, experience-based answers more valuable. For instance, when a peer asked about Meteor’s reactivity, I shared insights from my practice WODs rather than consulting AI. This approach fostered meaningful dialogue but limited my ability to provide quick, comprehensive answers for unfamiliar topics.

  Asking or Answering a Smart-QuestionSimilarly, I avoided using AI for smart-questions on platforms like Discord, where context-specific advice from peers working under identical conditions (e.g., same IDE, OS, or AI tools) was more relevant. While AI informed my background knowledge, I relied on personal or peer insights to craft or respond to smart-questions, ensuring authenticity and relevance. The limitation was the time required to formulate answers without AI’s speed, but the benefit was contextually grounded advice.

  Coding ExampleAI was highly effective for generating coding examples to deepen topic understanding. For instance, to explore Underscore’s .pluck method, I prompted ChatGPT: “Provide a code example using Underscore’s .pluck with sample input and output.” The example clarified the method’s utility, and the accompanying output solidified my understanding. However, ChatGPT occasionally produced outdated or verbose examples, requiring cross-referencing with Grok for accuracy.

  Explaining CodeAI excelled at explaining complex code, particularly for advanced techniques. During the final project, I used Grok to analyze a professor-provided solution with the prompt: “Explain this Meteor code line-by-line: [pasted code].” The detailed breakdown clarified reactive data flows, enhancing my ability to adapt the code. The benefit was a deeper understanding of abstract concepts, though AI sometimes overexplained basic elements, necessitating targeted prompts.

  Writing CodeCode generation was AI’s most utilized feature. For a WOD requiring a REST API, I prompted Grok: “Write a Node.js REST API endpoint using Express to handle [WOD requirements].” The generated code was syntactically correct and functional, saving significant development time. However, achieving precise outputs required iterative prompting, as initial responses sometimes included extraneous features. The nuance of crafting effective prompts was a learning curve but critical to maximizing AI’s utility.

  Documenting CodeAI often included explanatory comments in generated code, which I explicitly requested for complex tasks. For the final project, I prompted: “Generate a Meteor login function with detailed comments explaining each section.” Grok’s commented code was invaluable for tracking changes during iterative development. However, default comments were sometimes generic, requiring additional prompts to align with project-specific needs.

  Quality AssuranceAI streamlined quality assurance, particularly for resolving ESLint errors and ensuring clean builds. For a project file with ESLint issues, I prompted ChatGPT: “Fix the ESLint errors in this JavaScript code: [pasted code].” The corrected code expedited testing, though ChatGPT occasionally misaligned with our project’s ESLint configuration, necessitating manual adjustments. Grok was more reliable for such tasks, reducing errors and build times.

  Other Uses in ICS 314Beyond the listed elements, I used AI to explore software engineering tools recommended for ICS 314. For example, I prompted Grok: “Suggest tools for managing a Meteor project and explain their setup.” The response introduced me to tools like VS Code extensions, enhancing my workflow. This exploratory use was highly beneficial, though it required filtering AI’s suggestions for relevance to our course context.


## III. Impact on Learning and Understanding
  The integration of AI significantly enhanced my learning experience in ICS 314. By accelerating task completion, AI reduced the cognitive load of trial-and-error, allowing me to focus on conceptual understanding and skill development. For instance, Grok’s reliable code generation exposed me to multiple problem-solving approaches, deepening my grasp of software engineering principles like modularity and reactivity. AI also improved my problem-solving abilities by providing immediate feedback on code errors, fostering a proactive debugging mindset.
  
  However, AI posed challenges to deep comprehension when overused. Relying on generated code without thorough analysis occasionally led to surface-level understanding, particularly in early WODs. To counter this, I prioritized reviewing AI outputs to internalize logic, which ultimately strengthened my coding proficiency. Overall, AI enhanced my understanding by providing accessible, interactive learning resources, though it required mindful use to avoid dependency.
  
## IV. Practical Applications
  Beyond ICS 314, AI has practical applications in real-world software engineering. For example, in the Hawaiʻi Annual Code Challenge (HACC), AI could assist in rapid prototyping, debugging, and integrating APIs for civic solutions. In professional settings, AI tools like GitHub Copilot streamline code reviews and automate repetitive tasks, improving productivity. My experience using AI for GitHub workflow optimization in the final project mirrors these applications, demonstrating AI’s ability to enhance collaboration and efficiency. However, AI’s effectiveness depends on context; it excels in well-defined tasks but struggles with ambiguous or environment-specific challenges, as seen in my project’s login issues.

## V. Challenges and Opportunities
  AI’s primary challenges in ICS 314 included its lack of contextual retention and occasional rigidity. Both ChatGPT and Grok struggled to recall prior interactions within a session, requiring repetitive prompts to maintain project-specific parameters. Additionally, AI sometimes fixated on suboptimal solutions, necessitating session resets to explore new approaches. For example, when debugging a Meteor server issue, Grok repeatedly suggested the same incorrect configuration despite my clarifications.

  Opportunities for AI integration include enhancing contextual memory to support long-term projects and developing course-specific AI models trained on ICS 314 materials. Such advancements could provide tailored guidance, reducing prompt engineering overhead and improving response relevance. Additionally, integrating AI-driven code review tools into the course could further streamline quality assurance and foster best practices.

## VI. Comparative Analysis
  Traditional teaching methods, such as lectures and textbook readings, provide structured, foundational knowledge but often lack interactivity. In contrast, AI-enhanced approaches offer dynamic, on-demand support, enabling students to explore concepts at their own pace. For instance, AI’s ability to generate coding examples surpassed static textbook snippets, fostering engagement through immediate application. However, traditional methods excel in fostering critical thinking through in-class discussions, which AI cannot replicate.

  Regarding knowledge retention, AI’s interactive nature reinforced concepts through practical application, but over-reliance risked rote learning. Traditional methods, while slower, encouraged deeper internalization through manual problem-solving. For practical skill development, AI’s code generation and debugging support accelerated hands-on learning, giving it an edge over traditional approaches, which rely on slower, instructor-led feedback. A hybrid approach, blending AI’s interactivity with traditional rigor, would optimize engagement, retention, and skill acquisition.

## VII. Future Considerations
  The future of AI in software engineering education is promising but requires careful navigation. Advancements in contextual AI models could enable seamless integration into coursework, providing real-time, project-aware assistance. However, challenges include mitigating over-reliance, which could undermine critical thinking, and ensuring equitable access to premium AI tools like SuperGrok. Educators should establish guidelines for ethical AI use, emphasizing its role as a learning aid rather than a shortcut. Additionally, incorporating AI literacy into curricula will prepare students to leverage these tools effectively in professional settings. By balancing innovation with pedagogical integrity, AI can enhance software engineering education without compromising foundational skills.

## VIII. Conclusion
  AI has profoundly shaped my experience in ICS 314, serving as a versatile tool for code generation, debugging, concept exploration, and project management. Tools like Grok and ChatGPT have accelerated task completion, deepened my understanding of software engineering concepts, and prepared me for real-world applications. While challenges like contextual limitations and over-reliance persist, the opportunities for AI’s integration into education are vast, from tailored course assistants to advanced code review systems. To optimize AI’s role, educators should promote mindful usage, blending its capabilities with traditional teaching to foster both technical proficiency and critical thinking. My experiences underscore AI’s transformative potential, and I recommend its continued, guided integration into software engineering curricula to enhance learning outcomes and prepare students for an AI-driven future.
